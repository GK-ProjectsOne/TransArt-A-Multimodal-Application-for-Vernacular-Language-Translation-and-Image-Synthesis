{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gradio APP"
      ],
      "metadata": {
        "id": "b7x-DYh2EfRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdGl3rVdYWrw",
        "outputId": "8fc5e343-3821-474c-f4f3-d1221705f617",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.8 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "# Install the required libraries\n",
        "!pip install transformers gradio Pillow requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from transformers import MarianMTModel, MarianTokenizer, AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image, ImageDraw\n",
        "import io\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Detect if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the MarianMT model and tokenizer for translation (Tamil to English)\n",
        "model_name = \"Helsinki-NLP/opus-mt-mul-en\"\n",
        "translation_model = MarianMTModel.from_pretrained(model_name).to(device)\n",
        "translation_tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load GPT-Neo for creative text generation\n",
        "text_generation_model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
        "text_generation_model = AutoModelForCausalLM.from_pretrained(text_generation_model_name).to(device)\n",
        "text_generation_tokenizer = AutoTokenizer.from_pretrained(text_generation_model_name)\n",
        "\n",
        "# Add padding token to GPT-Neo tokenizer if not present\n",
        "if text_generation_tokenizer.pad_token is None:\n",
        "    text_generation_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Set your Hugging Face API key\n",
        "os.environ['HF_API_KEY'] = 'Your_HF_TOKEN'  # Replace with your actual API key\n",
        "api_key = os.getenv('HF_API_KEY')\n",
        "if api_key is None:\n",
        "    raise ValueError(\"Hugging Face API key is not set. Please set it in your environment.\")\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "# Define the API URL for image generation (replace with actual model URL)\n",
        "API_URL = \"https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell\"  # Replace with a valid image generation model\n",
        "\n",
        "# Query Hugging Face API to generate image with error handling\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Received status code {response.status_code}\")\n",
        "        print(f\"Response: {response.text}\")\n",
        "        return None\n",
        "    return response.content\n",
        "\n",
        "# Translate Tamil text to English\n",
        "def translate_text(tamil_text):\n",
        "    inputs = translation_tokenizer(tamil_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    translated_tokens = translation_model.generate(**inputs)\n",
        "    translation = translation_tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
        "    return translation\n",
        "\n",
        "# Generate an image based on the translated text with error handling\n",
        "def generate_image(prompt):\n",
        "    image_bytes = query({\"inputs\": prompt})\n",
        "\n",
        "    if image_bytes is None:\n",
        "        # Return a blank image with error message\n",
        "        error_img = Image.new('RGB', (300, 300), color=(255, 0, 0))\n",
        "        d = ImageDraw.Draw(error_img)\n",
        "        d.text((10, 150), \"Image Generation Failed\", fill=(255, 255, 255))\n",
        "        return error_img\n",
        "\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        # Return an error image in case of failure\n",
        "        error_img = Image.new('RGB', (300, 300), color=(255, 0, 0))\n",
        "        d = ImageDraw.Draw(error_img)\n",
        "        d.text((10, 150), \"Invalid Image Data\", fill=(255, 255, 255))\n",
        "        return error_img\n",
        "\n",
        "# Generate creative text based on the translated English text\n",
        "def generate_creative_text(translated_text):\n",
        "    inputs = text_generation_tokenizer(translated_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    generated_tokens = text_generation_model.generate(**inputs, max_length=100)\n",
        "    creative_text = text_generation_tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "    return creative_text\n",
        "\n",
        "# Function to handle the full workflow\n",
        "def translate_generate_image_and_text(tamil_text):\n",
        "    # Step 1: Translate Tamil to English\n",
        "    translated_text = translate_text(tamil_text)\n",
        "\n",
        "    # Step 2: Generate an image from the translated text\n",
        "    image = generate_image(translated_text)\n",
        "\n",
        "    # Step 3: Generate creative text from the translated text\n",
        "    creative_text = generate_creative_text(translated_text)\n",
        "\n",
        "    return translated_text, creative_text, image\n",
        "\n",
        "# Create a visually appealing Gradio interface\n",
        "css = \"\"\"\n",
        "#transart-title {\n",
        "    font-size: 2.5em;\n",
        "    font-weight: bold;\n",
        "    color: #4CAF50;\n",
        "    text-align: center;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "#transart-subtitle {\n",
        "    font-size: 1.25em;\n",
        "    text-align: center;\n",
        "    color: #555555;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "body {\n",
        "    background-color: #f0f0f5;\n",
        "}\n",
        ".gradio-container {\n",
        "    font-family: 'Arial', sans-serif;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Custom HTML for title and subtitle (can be displayed in Markdown)\n",
        "title_markdown = \"\"\"\n",
        "# <div id=\"transart-title\">TransArt</div>\n",
        "### <div id=\"transart-subtitle\">Tamil to English Translation, Creative Text & Image Generation</div>\n",
        "\"\"\"\n",
        "\n",
        "# Gradio interface with customized layout and aesthetics\n",
        "with gr.Blocks(css=css) as interface:\n",
        "    gr.Markdown(title_markdown)  # Title and subtitle in Markdown\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            tamil_input = gr.Textbox(label=\"Enter Tamil Text\", placeholder=\"Type Tamil text here...\", lines=3)  # Input for Tamil text\n",
        "        with gr.Column():\n",
        "            translated_output = gr.Textbox(label=\"Translated Text\", interactive=False)        # Output for translated text\n",
        "            creative_text_output = gr.Textbox(label=\"Creative Generated Text\", interactive=False)  # Output for creative text\n",
        "            generated_image_output = gr.Image(label=\"Generated Image\")  # Output for generated image\n",
        "\n",
        "    gr.Button(\"Generate\").click(fn=translate_generate_image_and_text, inputs=tamil_input, outputs=[translated_output, creative_text_output, generated_image_output])\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch(debug=True, server_name=\"0.0.0.0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4f40b686c25441268096f8ee27189585",
            "897f975e49b4484f99bf73f5d04df3cc",
            "7a82bd4b9bd946fb81768ee889985ff0",
            "62884eb17e014244a216017346e73186",
            "37b83a728dc84f20a8220d10a87fa0b3",
            "fdfae18f406c4915a742694886bdf886",
            "4bba9bdb883d4aceae5adaddee07e532",
            "7a5c03cd94544b4da3467437ccbe69bc",
            "1fb990988a074d85b96de8390d9ec781",
            "ae9ee30dd4c44758943c98e1aa8cb1e2",
            "d8b766d087e54967812a0e2243dca06d",
            "1b173cddb7334683b530631c0fb1d75f",
            "9e81df6dd7f4483e84f09b59203094dc",
            "0cc2e30bfc134ba8be4f8458bde24d8e",
            "8b471a624a7d437e9868967b8dd9e455",
            "3ed995a61b0747e88b987c0aae797c68",
            "86cbe16ff57e466eaa80f3b6a2b45fed",
            "64cdd3b90be84bee9eea23ad49969a02",
            "2652be50a1ef431f8714ad46f199b738",
            "9442847d381145479704927736cf5816",
            "a8adae4ba2f34918a44e55a1d6841caf",
            "c64914a9a95748269e8591f1ea839aed",
            "f9fab9f959334d1080f5325ee0d066e2",
            "07d93859378846c69615543b5bebf451",
            "18ad13d97e4d4c67935666ffc0028edf",
            "5ef13e3df8b04688b541c67b729bc8dc",
            "6ff4329a0c354f87902cd9d44c7eb18a",
            "0f13b8cbb83846e3aae6bca032e9928f",
            "74bc90f47aab458c87de2db6511405ce",
            "861084af00f94ef3a3eaab609fd263ea",
            "b2bed4431dd3499dade21ec9668cc458",
            "eca957a1e20b48e49103e11d29f36a3f",
            "24a51bfa5fdd4aacb27f1e3c5dc93b44",
            "b7723e1a5c07485595d4a56d1bee367e",
            "f5b4e7b822c949efb44a81015b1c34aa",
            "e5f63797a7f648f19a7d4671890464e7",
            "b4bad2ee16664a4199ac549786576910",
            "8ac769ce7aac497e8d88c0ccf41442ce",
            "9d8649233ae24254b1b9d7ead1be8805",
            "edc7082f7eab40e0a8ed0fc302f08f7f",
            "d0614df4c0eb46beb5ef6dd3c478a17c",
            "257e62b33d4b450a81d7236b0c907098",
            "3a44c206e7934f55b7b2672a80d81156",
            "18d3712b69a645e1aa811e4f5b25df7f",
            "240f5afba69b4e3ba576acf65d4c879c",
            "6265b108496247769316a4bb60888fc3",
            "d0e22b717aa94c4b982bf178f4195a9e",
            "d51276ad945647108d296e8c52fa76b3",
            "3e520be9b34d446091f259f0605c25c7",
            "c16079de5d6a4aaba88de739f81b66f9",
            "86a6bd9b707f47798a99699751942f20",
            "30cd9b1194b04c38b2059670075c86df",
            "5915859748db425ba444036faf4019a1",
            "36e05df645fa45a8a72b12362a3d51d3",
            "3a0e65229ede4192a16f3759abd3c990",
            "c96e60d27ed34e37b485c3091681816d",
            "8fb26bd9d8294139bdd60ada1e96603d",
            "f3b83c67350d42e28ab2c5d61782e59c",
            "a75943ac5d44477183d459b7df1af537",
            "d578a8c9425f49b186a9882478159961",
            "31f289fab6cc434b8b6208217a24797e",
            "145483709f54425aa118411efb7e3c58",
            "5a7bdfcb81e34571a4cf1861545c5bc2",
            "79705dbd671d4d1cb90c923e35b1deb3",
            "ac64aa7ae8e249e7a3b7d8bc728ce62b",
            "20aff3121c3e4a209a638c8e1343e667",
            "660c64a7cdaf4fb287439945890f2fc4",
            "32c4019b557e455bb150c5c131339619",
            "cc0d041005c94b3fa8c6890216d317e2",
            "c3c4fccb5918413d987711b50f28a413",
            "bb105a76c3884b08956d4377df058c2f",
            "3e774a177c5e401fb23ab2f674920306",
            "7ce197515ed14e0aa28452842d507814",
            "4d1fb440479840fd9147badfc73111bc",
            "7f039ea704384719ba48daf3210730e3",
            "1a3c801582194a9e97823daf7ba15aaf",
            "524d15cd70454fb78e636a52f51c949f",
            "eed0fd9345ee4fc7812d335b8f5e6730",
            "6d8ab3df8f324426ab15bc2e6631703f",
            "4a98a0c9ef4349af90d8604f2b12e6c5",
            "e574047f2925420585f82988c3933e9e",
            "15221a238ec944b8b868960626f1259c",
            "9876f7ab653c4e869755e40db064a8c0",
            "3dba80448930480c8c24b517037c8d99",
            "22a5e81244a6447cb482e213d2529f48",
            "1ab98bf8ec71447381c23cca70aa54fb",
            "cbcf48a22fd749ceaef8297cec092a01",
            "08531a4dd59e4603aacbc19e60553bc5",
            "75eafe6c7fe54c079447e63dce31336d",
            "70497bc34015489d86e8bdcaaf3136ce",
            "c3e69428f0c24445bcd37fc0ecf68835",
            "5b15cdba89e7409593c7f15c987751c1",
            "5ad012425a224181a1e2ec17ddd95c5e",
            "41f6bb990e654675981d4eeffc3d07e8",
            "95a58768e9d04d668cfb70d2aea7ba36",
            "192464a38c484fc6bb08890acdc51187",
            "ebc1771fd35045199807b33e70277a3d",
            "126b35165f2d4336acc11b6167e7b045",
            "302b8c244b094975ac722986673cef0f",
            "e6937c2d38474476bf2f95f0fdc7d601",
            "ae9e2ffa18c44a5daf5510b8a5904ad5",
            "dee27b42a9974b159fc784f06c52ef7b",
            "9e7610b783134ad09dd95b6bfd97494c",
            "a3667b1057124c3fb9d2c7ec17d09fe9",
            "2cbb67242ed24c36b30bbeaed693e898",
            "664722498773427881b4f915351d6f68",
            "1171e40464644c8ba7381790666af6d3",
            "3bd38a5dcf3e4a778fd6217893a21909",
            "fef6bd93cc46481facfe6aff8d7bb4b5",
            "739c544ce9f6454bb5609549c25acccc",
            "7a50b01b373a40af995d53be04e3d447",
            "694153ea1cd24b1b8ccc33938bd05e5a",
            "3e7b29361c54428cb45e5dfe175cd1cf",
            "43fc4481f6634bf4a1d45214830f8912",
            "a8c8e1f623a14d189e31087f9ce04e02",
            "d9780a8cb2d14dce99d39227416ea2ec",
            "f98763df3c5840ad9c49f154a43afbd9",
            "665262afc68c45d38ea432036c007936",
            "1e83da9ecc1f4ec7a45221a9e19cfd2e",
            "0bf80f4953bc428288d6598ff48d6a9f",
            "f39835ac1d054eaa8fef51e186cd582d",
            "c8cca1a947014c18a09b85b07dabcd08",
            "3ff5ea4de39c48fab7a750c7ae173adf",
            "768aad02910b461d841906e094d3ec42",
            "748f190a7c8b4cd4813c0479788aace3",
            "cab78fa264a6400d94f620447b8696f2",
            "1fb05845bd2742908816917ba13ec5ee",
            "4f28e00c353442b89b662a0315733c08",
            "0a18353e455d4eb1ad427eab96b17204",
            "000590339d1444f8a11f59d4a0990fe6",
            "0c182925f30b4795adc681c55dbee3b8",
            "49226259b4a8446aa70d8b8b8bf9f957",
            "3a04888daa374a598f9d9deaa373d136",
            "b8ba890b92f24de0aca823da5d29c25e",
            "8131b31f1c7f4652a9ee9a9ff96dd47d",
            "80462cac142d4f38ac6e815f058dca94",
            "ac8e6936c6744520b5addd45a9c32c5c",
            "06f1ef855104415f81f371d596f1d24c",
            "ff076529b8aa487b84b62008dcff9518",
            "3fa3c419ac184bc68f7f54f6586ea761",
            "0a810a04ae134e07bdde35e9f0bfc173",
            "836a8bff54344c678274d555a430d052",
            "f77b6185fce5465a85ad51ed50886b46"
          ]
        },
        "id": "WUd-ZpZ5ChO_",
        "outputId": "fea75842-9181-44a5-bf1c-3153ab213e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f40b686c25441268096f8ee27189585"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/310M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b173cddb7334683b530631c0fb1d75f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9fab9f959334d1080f5325ee0d066e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7723e1a5c07485595d4a56d1bee367e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/707k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "240f5afba69b4e3ba576acf65d4c879c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/791k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c96e60d27ed34e37b485c3091681816d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "660c64a7cdaf4fb287439945890f2fc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed0fd9345ee4fc7812d335b8f5e6730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75eafe6c7fe54c079447e63dce31336d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6937c2d38474476bf2f95f0fdc7d601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a50b01b373a40af995d53be04e3d447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8cca1a947014c18a09b85b07dabcd08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a04888daa374a598f9d9deaa373d136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://245b986ece465b66d5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://245b986ece465b66d5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 0.0.0.0:7860 <> https://245b986ece465b66d5.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit Code"
      ],
      "metadata": {
        "id": "D4MNwF1IEjAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit requests"
      ],
      "metadata": {
        "id": "2TKd8w9zFO1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import streamlit as st\n",
        "import requests\n",
        "from getpass import getpass\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Input your Hugging Face and Groq tokens securely\n",
        "Transalate_token = getpass(\"Enter Hugging Face Translation Token: \")\n",
        "Image_Token = getpass(\"Enter Hugging Face Image Generation Token: \")\n",
        "Content_Token = getpass(\"Enter Groq Content Generation Token: \")\n",
        "Image_prompt_token = getpass(\"Enter Groq Prompt Generation Token: \")\n",
        "\n",
        "# API Headers\n",
        "Translate = {\"Authorization\": f\"Bearer {Transalate_token}\"}\n",
        "Image_generation = {\"Authorization\": f\"Bearer {Image_Token}\"}\n",
        "Content_generation = {\n",
        "    \"Authorization\": f\"Bearer {Content_Token}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "Image_Prompt = {\n",
        "    \"Authorization\": f\"Bearer {Image_prompt_token}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Translation Model API URL (Tamil to English)\n",
        "translation_url = \"https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-one-mmt\"\n",
        "\n",
        "# Text-to-Image Model API URLs\n",
        "image_generation_urls = {\n",
        "    \"black-forest-labs/FLUX.1-schnell\": \"https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell\",\n",
        "    \"CompVis/stable-diffusion-v1-4\": \"https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4\",\n",
        "    \"black-forest-labs/FLUX.1-dev\": \"https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-dev\"\n",
        "}\n",
        "\n",
        "# Content generation models\n",
        "content_models = {\n",
        "    \"llama-3.1-70b-versatile\": \"llama-3.1-70b-versatile\",\n",
        "    \"llama3-8b-8192\": \"llama3-8b-8192\",\n",
        "    \"gemma2-9b-it\": \"gemma2-9b-it\",\n",
        "    \"mixtral-8x7b-32768\": \"mixtral-8x7b-32768\"\n",
        "}\n",
        "\n",
        "# Function to query Hugging Face translation model\n",
        "def translate_text(text):\n",
        "    payload = {\"inputs\": text}\n",
        "    response = requests.post(translation_url, headers=Translate, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        translated_text = result[0]['generated_text']\n",
        "        return translated_text\n",
        "    else:\n",
        "        return f\"Translation Error {response.status_code}: {response.text}\"\n",
        "\n",
        "# Function to query Groq content generation model\n",
        "def generate_content(english_text, max_tokens, temperature, model):\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative and insightful writer.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Write educational content about {english_text} within {max_tokens} tokens.\"}\n",
        "        ],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature\n",
        "    }\n",
        "    response = requests.post(url, json=payload, headers=Content_generation)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result['choices'][0]['message']['content']\n",
        "    else:\n",
        "        return f\"Content Generation Error: {response.status_code}\"\n",
        "\n",
        "# Function to generate image prompt\n",
        "def generate_image_prompt(english_text):\n",
        "    payload = {\n",
        "        \"model\": \"mixtral-8x7b-32768\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional Text to image prompt generator.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Create a text to image generation prompt about {english_text} within 30 tokens.\"}\n",
        "        ],\n",
        "        \"max_tokens\": 30\n",
        "    }\n",
        "    response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", json=payload, headers=Image_Prompt)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result['choices'][0]['message']['content']\n",
        "    else:\n",
        "        return f\"Prompt Generation Error: {response.status_code}\"\n",
        "\n",
        "# Function to generate an image from the prompt\n",
        "def generate_image(image_prompt, model_url):\n",
        "    data = {\"inputs\": image_prompt}\n",
        "    response = requests.post(model_url, headers=Image_generation, json=data)\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        return f\"Image Generation Error {response.status_code}: {response.text}\"\n",
        "\n",
        "# Streamlit App\n",
        "def main():\n",
        "    st.title(\"\")\n",
        "    st.write(\"Translate Tamil to English, generate educational content, and generate related images!\")\n",
        "\n",
        "    # Input Section\n",
        "    tamil_input = st.text_area(\"Enter Tamil Text\")\n",
        "    temperature = st.slider(\"Temperature\", min_value=0.1, max_value=1.0, value=0.7)\n",
        "    max_tokens = st.slider(\"Max Tokens for Content Generation\", min_value=100, max_value=400, value=200)\n",
        "    content_model = st.selectbox(\"Select Content Generation Model\", list(content_models.keys()))\n",
        "    image_model = st.selectbox(\"Select Image Generation Model\", list(image_generation_urls.keys()))\n",
        "\n",
        "    if st.button(\"Generate\"):\n",
        "        # Step 1: Translation (Tamil to English)\n",
        "        english_text = translate_text(tamil_input)\n",
        "\n",
        "        # Step 2: Generate Educational Content\n",
        "        content_output = generate_content(english_text, max_tokens, temperature, content_models[content_model])\n",
        "\n",
        "        # Step 3: Generate Image from the prompt\n",
        "        image_prompt = generate_image_prompt(english_text)\n",
        "        image_data = generate_image(image_prompt, image_generation_urls[image_model])\n",
        "\n",
        "        # Display Results\n",
        "        st.subheader(\"Translated English Text\")\n",
        "        st.write(english_text)\n",
        "\n",
        "        st.subheader(\"Generated Content\")\n",
        "        st.write(content_output)\n",
        "\n",
        "        # Display Generated Image\n",
        "        if isinstance(image_data, bytes):\n",
        "            image = Image.open(io.BytesIO(image_data))\n",
        "            st.image(image, caption='Generated Image', use_column_width=True)\n",
        "        else:\n",
        "            st.error(image_data)\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "okQ-Mb14Q4Yc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}